# @package _global_

# usage: +experiment=moco

defaults:
    - override /dm: whaledo
    - override /backbone: beit
    - override /alg: moco
    - override /logger: whaledo
    - _self_

backbone:
  pretrained: true

dm: 
  test_prop: 0.1
  image_size: 224
  training_mode: step
  train_batch_size: 32
  train_transforms: 
    _target_: torchvision.transforms.Compose
    transforms: 
    # - _target_: whaledo.transforms.ResizeAndPadToSize
    #   size: ${ dm.image_size }
    # - _target_: whaledo.transforms.MultiCropTransform.with_dino_transform
    #   global_crop_size: ${ dm.image_size }
    #   local_crops_number: 0
    - _target_: whaledo.transforms.MultiCropTransform.with_whaledo_transform
      global_crop_size: ${ dm.image_size }

trainer:
  max_steps: 10000
  multiple_trainloader_mode: 'min_size'
  val_check_interval: 500
  precision: 16
  accumulate_grad_batches: null

alg:
  lr: 1e-4
  proj_dim: 128
  mlp_head: true
  loss_fn: SUPCON
  temp0: 1.0
  dcl: true
  mb_capacity: 8192
  ema_warmup_steps: ${ trainer.max_steps } 
  ema_decay_start: 0.96
  ema_decay_end: 1.0
  scheduler_cls: whaledo.schedulers.CosineLRWithLinearWarmup
  scheduler_kwargs:
    warmup_iters: 1000
    total_iters: ${ trainer.max_steps }
    lr_start: 5e-7

logger:
  group: moco

